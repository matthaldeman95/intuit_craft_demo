***REMOVED***
A place for code to be called from core C-code.

Some things are more easily handled Python.

***REMOVED***
from __future__ import division, absolute_import, print_function

import re
import sys

from numpy.compat import asbytes, basestring
from .multiarray import dtype, array, ndarray
import ctypes
from .numerictypes import object_

if (sys.byteorder == 'little'***REMOVED***:
    _nbo = asbytes('<'***REMOVED***
else:
    _nbo = asbytes('>'***REMOVED***

def _makenames_list(adict, align***REMOVED***:
    allfields = [***REMOVED***
    fnames = list(adict.keys(***REMOVED******REMOVED***
    for fname in fnames:
        obj = adict[fname***REMOVED***
        n = len(obj***REMOVED***
        if not isinstance(obj, tuple***REMOVED*** or n not in [2, 3***REMOVED***:
            raise ValueError("entry not a 2- or 3- tuple"***REMOVED***
        if (n > 2***REMOVED*** and (obj[2***REMOVED*** == fname***REMOVED***:
            continue
        num = int(obj[1***REMOVED******REMOVED***
        if (num < 0***REMOVED***:
            raise ValueError("invalid offset."***REMOVED***
        format = dtype(obj[0***REMOVED***, align=align***REMOVED***
        if (format.itemsize == 0***REMOVED***:
            raise ValueError("all itemsizes must be fixed."***REMOVED***
        if (n > 2***REMOVED***:
            title = obj[2***REMOVED***
        else:
            title = None
        allfields.append((fname, format, num, title***REMOVED******REMOVED***
    # sort by offsets
    allfields.sort(key=lambda x: x[2***REMOVED******REMOVED***
    names = [x[0***REMOVED*** for x in allfields***REMOVED***
    formats = [x[1***REMOVED*** for x in allfields***REMOVED***
    offsets = [x[2***REMOVED*** for x in allfields***REMOVED***
    titles = [x[3***REMOVED*** for x in allfields***REMOVED***

    return names, formats, offsets, titles

# Called in PyArray_DescrConverter function when
#  a dictionary without "names" and "formats"
#  fields is used as a data-type descriptor.
def _usefields(adict, align***REMOVED***:
    ***REMOVED***
        names = adict[-1***REMOVED***
    except KeyError:
        names = None
    if names is None:
        names, formats, offsets, titles = _makenames_list(adict, align***REMOVED***
    else:
        formats = [***REMOVED***
        offsets = [***REMOVED***
        titles = [***REMOVED***
        for name in names:
            res = adict[name***REMOVED***
            formats.append(res[0***REMOVED******REMOVED***
            offsets.append(res[1***REMOVED******REMOVED***
            if (len(res***REMOVED*** > 2***REMOVED***:
                titles.append(res[2***REMOVED******REMOVED***
            else:
                titles.append(None***REMOVED***

    return dtype({"names": names,
                  "formats": formats,
                  "offsets": offsets,
                  "titles": titles***REMOVED***, align***REMOVED***


# construct an array_protocol descriptor list
#  from the fields attribute of a descriptor
# This calls itself recursively but should eventually hit
#  a descriptor that has no fields and then return
#  a simple typestring

def _array_descr(descriptor***REMOVED***:
    fields = descriptor.fields
    if fields is None:
        subdtype = descriptor.subdtype
        if subdtype is None:
            if descriptor.metadata is None:
                return descriptor.str
            else:
                new = descriptor.metadata.copy(***REMOVED***
                if new:
                    return (descriptor.str, new***REMOVED***
                else:
                    return descriptor.str
        else:
            return (_array_descr(subdtype[0***REMOVED******REMOVED***, subdtype[1***REMOVED******REMOVED***

    names = descriptor.names
    ordered_fields = [fields[x***REMOVED*** + (x,***REMOVED*** for x in names***REMOVED***
    result = [***REMOVED***
    offset = 0
    for field in ordered_fields:
        if field[1***REMOVED*** > offset:
            num = field[1***REMOVED*** - offset
            result.append(('', '|V%d' % num***REMOVED******REMOVED***
            offset += num
        if len(field***REMOVED*** > 3:
            name = (field[2***REMOVED***, field[3***REMOVED******REMOVED***
        else:
            name = field[2***REMOVED***
        if field[0***REMOVED***.subdtype:
            tup = (name, _array_descr(field[0***REMOVED***.subdtype[0***REMOVED******REMOVED***,
                   field[0***REMOVED***.subdtype[1***REMOVED******REMOVED***
        else:
            tup = (name, _array_descr(field[0***REMOVED******REMOVED******REMOVED***
        offset += field[0***REMOVED***.itemsize
        result.append(tup***REMOVED***

    if descriptor.itemsize > offset:
        num = descriptor.itemsize - offset
        result.append(('', '|V%d' % num***REMOVED******REMOVED***

    return result

# Build a new array from the information in a pickle.
# Note that the name numpy.core._internal._reconstruct is embedded in
# pickles of ndarrays made with NumPy before release 1.0
# so don't remove the name here, or you'll
# break backward compatibilty.
def _reconstruct(subtype, shape, dtype***REMOVED***:
    return ndarray.__new__(subtype, shape, dtype***REMOVED***


# format_re was originally from numarray by J. Todd Miller

format_re = re.compile(asbytes(
                           r'(?P<order1>[<>|=***REMOVED***?***REMOVED***'
                           r'(?P<repeats> *[(***REMOVED***?[ ,0-9L***REMOVED****[***REMOVED******REMOVED***? ****REMOVED***'
                           r'(?P<order2>[<>|=***REMOVED***?***REMOVED***'
                           r'(?P<dtype>[A-Za-z0-9.?***REMOVED****(?:\[[a-zA-Z0-9,.***REMOVED***+\***REMOVED******REMOVED***?***REMOVED***'***REMOVED******REMOVED***
sep_re = re.compile(asbytes(r'\s*,\s*'***REMOVED******REMOVED***
space_re = re.compile(asbytes(r'\s+$'***REMOVED******REMOVED***

# astr is a string (perhaps comma separated***REMOVED***

_convorder = {asbytes('='***REMOVED***: _nbo***REMOVED***

def _commastring(astr***REMOVED***:
    startindex = 0
    result = [***REMOVED***
    while startindex < len(astr***REMOVED***:
        mo = format_re.match(astr, pos=startindex***REMOVED***
        ***REMOVED***
            (order1, repeats, order2, dtype***REMOVED*** = mo.groups(***REMOVED***
        except (TypeError, AttributeError***REMOVED***:
            raise ValueError('format number %d of "%s" is not recognized' %
                                            (len(result***REMOVED***+1, astr***REMOVED******REMOVED***
        startindex = mo.end(***REMOVED***
        # Separator or ending padding
        if startindex < len(astr***REMOVED***:
            if space_re.match(astr, pos=startindex***REMOVED***:
                startindex = len(astr***REMOVED***
            else:
                mo = sep_re.match(astr, pos=startindex***REMOVED***
                if not mo:
                    raise ValueError(
                        'format number %d of "%s" is not recognized' %
                        (len(result***REMOVED***+1, astr***REMOVED******REMOVED***
                startindex = mo.end(***REMOVED***

        if order2 == asbytes(''***REMOVED***:
            order = order1
        elif order1 == asbytes(''***REMOVED***:
            order = order2
        else:
            order1 = _convorder.get(order1, order1***REMOVED***
            order2 = _convorder.get(order2, order2***REMOVED***
            if (order1 != order2***REMOVED***:
                raise ValueError(
                    'inconsistent byte-order specification %s and %s' %
                    (order1, order2***REMOVED******REMOVED***
            order = order1

        if order in [asbytes('|'***REMOVED***, asbytes('='***REMOVED***, _nbo***REMOVED***:
            order = asbytes(''***REMOVED***
        dtype = order + dtype
        if (repeats == asbytes(''***REMOVED******REMOVED***:
            newitem = dtype
        else:
            newitem = (dtype, eval(repeats***REMOVED******REMOVED***
        result.append(newitem***REMOVED***

    return result

def _getintp_ctype(***REMOVED***:
    val = _getintp_ctype.cache
    if val is not None:
        return val
    char = dtype('p'***REMOVED***.char
    if (char == 'i'***REMOVED***:
        val = ctypes.c_int
    elif char == 'l':
        val = ctypes.c_long
    elif char == 'q':
        val = ctypes.c_longlong
    else:
        val = ctypes.c_long
    _getintp_ctype.cache = val
    return val
_getintp_ctype.cache = None

# Used for .ctypes attribute of ndarray

class _missing_ctypes(object***REMOVED***:
    def cast(self, num, obj***REMOVED***:
        return num

    def c_void_p(self, num***REMOVED***:
        return num

class _ctypes(object***REMOVED***:
    def __init__(self, array, ptr=None***REMOVED***:
        ***REMOVED***
            self._ctypes = ctypes
        except ImportError:
            self._ctypes = _missing_ctypes(***REMOVED***
        self._arr = array
        self._data = ptr
        if self._arr.ndim == 0:
            self._zerod = True
        else:
            self._zerod = False

    def data_as(self, obj***REMOVED***:
        return self._ctypes.cast(self._data, obj***REMOVED***

    def shape_as(self, obj***REMOVED***:
        if self._zerod:
            return None
        return (obj*self._arr.ndim***REMOVED***(*self._arr.shape***REMOVED***

    def strides_as(self, obj***REMOVED***:
        if self._zerod:
            return None
        return (obj*self._arr.ndim***REMOVED***(*self._arr.strides***REMOVED***

    def get_data(self***REMOVED***:
        return self._data

    def get_shape(self***REMOVED***:
        if self._zerod:
            return None
        return (_getintp_ctype(***REMOVED****self._arr.ndim***REMOVED***(*self._arr.shape***REMOVED***

    def get_strides(self***REMOVED***:
        if self._zerod:
            return None
        return (_getintp_ctype(***REMOVED****self._arr.ndim***REMOVED***(*self._arr.strides***REMOVED***

    def get_as_parameter(self***REMOVED***:
        return self._ctypes.c_void_p(self._data***REMOVED***

    data = property(get_data, None, doc="c-types data"***REMOVED***
    shape = property(get_shape, None, doc="c-types shape"***REMOVED***
    strides = property(get_strides, None, doc="c-types strides"***REMOVED***
    _as_parameter_ = property(get_as_parameter, None, doc="_as parameter_"***REMOVED***


# Given a datatype and an order object
#  return a new names tuple
#  with the order indicated
def _newnames(datatype, order***REMOVED***:
    oldnames = datatype.names
    nameslist = list(oldnames***REMOVED***
    if isinstance(order, str***REMOVED***:
        order = [order***REMOVED***
    if isinstance(order, (list, tuple***REMOVED******REMOVED***:
        for name in order:
            ***REMOVED***
                nameslist.remove(name***REMOVED***
            except ValueError:
                raise ValueError("unknown field name: %s" % (name,***REMOVED******REMOVED***
        return tuple(list(order***REMOVED*** + nameslist***REMOVED***
    raise ValueError("unsupported order value: %s" % (order,***REMOVED******REMOVED***

def _copy_fields(ary***REMOVED***:
    ***REMOVED***Return copy of structured array with padding between fields removed.

    Parameters
    ----------
    ary : ndarray
       Structured array from which to remove padding bytes

    Returns
    -------
    ary_copy : ndarray
       Copy of ary with padding bytes removed
    ***REMOVED***
    dt = ary.dtype
    copy_dtype = {'names': dt.names,
                  'formats': [dt.fields[name***REMOVED***[0***REMOVED*** for name in dt.names***REMOVED******REMOVED***
    return array(ary, dtype=copy_dtype, copy=True***REMOVED***

def _getfield_is_safe(oldtype, newtype, offset***REMOVED***:
    ***REMOVED*** Checks safety of getfield for object arrays.

    As in _view_is_safe, we need to check that memory containing objects is not
    reinterpreted as a non-object datatype and vice versa.

    Parameters
    ----------
    oldtype : data-type
        Data type of the original ndarray.
    newtype : data-type
        Data type of the field being accessed by ndarray.getfield
    offset : int
        Offset of the field being accessed by ndarray.getfield

    Raises
    ------
    TypeError
        If the field access is invalid

    ***REMOVED***
    if newtype.hasobject or oldtype.hasobject:
        if offset == 0 and newtype == oldtype:
            return
        if oldtype.names:
            for name in oldtype.names:
                if (oldtype.fields[name***REMOVED***[1***REMOVED*** == offset and
                        oldtype.fields[name***REMOVED***[0***REMOVED*** == newtype***REMOVED***:
                    return
        raise TypeError("Cannot get/set field of an object array"***REMOVED***
    return

def _view_is_safe(oldtype, newtype***REMOVED***:
    ***REMOVED*** Checks safety of a view involving object arrays, for example when
    doing::

        np.zeros(10, dtype=oldtype***REMOVED***.view(newtype***REMOVED***

    Parameters
    ----------
    oldtype : data-type
        Data type of original ndarray
    newtype : data-type
        Data type of the view

    Raises
    ------
    TypeError
        If the new type is incompatible with the old type.

    ***REMOVED***

    # if the types are equivalent, there is no problem.
    # for example: dtype((np.record, 'i4,i4'***REMOVED******REMOVED*** == dtype((np.void, 'i4,i4'***REMOVED******REMOVED***
    if oldtype == newtype:
        return

    if newtype.hasobject or oldtype.hasobject:
        raise TypeError("Cannot change data-type for object array."***REMOVED***
    return

# Given a string containing a PEP 3118 format specifier,
# construct a Numpy dtype

_pep3118_native_map = {
    '?': '?',
    'b': 'b',
    'B': 'B',
    'h': 'h',
    'H': 'H',
    'i': 'i',
    'I': 'I',
    'l': 'l',
    'L': 'L',
    'q': 'q',
    'Q': 'Q',
    'e': 'e',
    'f': 'f',
    'd': 'd',
    'g': 'g',
    'Zf': 'F',
    'Zd': 'D',
    'Zg': 'G',
    's': 'S',
    'w': 'U',
    'O': 'O',
    'x': 'V',  # padding
***REMOVED***
_pep3118_native_typechars = ''.join(_pep3118_native_map.keys(***REMOVED******REMOVED***

_pep3118_standard_map = {
    '?': '?',
    'b': 'b',
    'B': 'B',
    'h': 'i2',
    'H': 'u2',
    'i': 'i4',
    'I': 'u4',
    'l': 'i4',
    'L': 'u4',
    'q': 'i8',
    'Q': 'u8',
    'e': 'f2',
    'f': 'f',
    'd': 'd',
    'Zf': 'F',
    'Zd': 'D',
    's': 'S',
    'w': 'U',
    'O': 'O',
    'x': 'V',  # padding
***REMOVED***
_pep3118_standard_typechars = ''.join(_pep3118_standard_map.keys(***REMOVED******REMOVED***

def _dtype_from_pep3118(spec, byteorder='@', is_subdtype=False***REMOVED***:
    fields = {***REMOVED***
    offset = 0
    explicit_name = False
    this_explicit_name = False
    common_alignment = 1
    is_padding = False

    dummy_name_index = [0***REMOVED***

    def next_dummy_name(***REMOVED***:
        dummy_name_index[0***REMOVED*** += 1

    def get_dummy_name(***REMOVED***:
        while True:
            name = 'f%d' % dummy_name_index[0***REMOVED***
            if name not in fields:
                return name
            next_dummy_name(***REMOVED***

    # Parse spec
    while spec:
        value = None

        # End of structure, bail out to upper level
        if spec[0***REMOVED*** == '***REMOVED***':
            spec = spec[1:***REMOVED***
            break

        # Sub-arrays (1***REMOVED***
        shape = None
        if spec[0***REMOVED*** == '(':
            j = spec.index('***REMOVED***'***REMOVED***
            shape = tuple(map(int, spec[1:j***REMOVED***.split(','***REMOVED******REMOVED******REMOVED***
            spec = spec[j+1:***REMOVED***

        # Byte order
        if spec[0***REMOVED*** in ('@', '=', '<', '>', '^', '!'***REMOVED***:
            byteorder = spec[0***REMOVED***
            if byteorder == '!':
                byteorder = '>'
            spec = spec[1:***REMOVED***

        # Byte order characters also control native vs. standard type sizes
        if byteorder in ('@', '^'***REMOVED***:
            type_map = _pep3118_native_map
            type_map_chars = _pep3118_native_typechars
        else:
            type_map = _pep3118_standard_map
            type_map_chars = _pep3118_standard_typechars

        # Item sizes
        itemsize = 1
        if spec[0***REMOVED***.isdigit(***REMOVED***:
            j = 1
            for j in range(1, len(spec***REMOVED******REMOVED***:
                if not spec[j***REMOVED***.isdigit(***REMOVED***:
                    break
            itemsize = int(spec[:j***REMOVED******REMOVED***
            spec = spec[j:***REMOVED***

        # Data types
        is_padding = False

        if spec[:2***REMOVED*** == 'T{':
            value, spec, align, next_byteorder = _dtype_from_pep3118(
                spec[2:***REMOVED***, byteorder=byteorder, is_subdtype=True***REMOVED***
        elif spec[0***REMOVED*** in type_map_chars:
            next_byteorder = byteorder
            if spec[0***REMOVED*** == 'Z':
                j = 2
            else:
                j = 1
            typechar = spec[:j***REMOVED***
            spec = spec[j:***REMOVED***
            is_padding = (typechar == 'x'***REMOVED***
            dtypechar = type_map[typechar***REMOVED***
            if dtypechar in 'USV':
                dtypechar += '%d' % itemsize
                itemsize = 1
            numpy_byteorder = {'@': '=', '^': '='***REMOVED***.get(byteorder, byteorder***REMOVED***
            value = dtype(numpy_byteorder + dtypechar***REMOVED***
            align = value.alignment
        else:
            raise ValueError("Unknown PEP 3118 data type specifier %r" % spec***REMOVED***

        #
        # Native alignment may require padding
        #
        # Here we assume that the presence of a '@' character implicitly implies
        # that the start of the array is *already* aligned.
        #
        extra_offset = 0
        if byteorder == '@':
            start_padding = (-offset***REMOVED*** % align
            intra_padding = (-value.itemsize***REMOVED*** % align

            offset += start_padding

            if intra_padding != 0:
                if itemsize > 1 or (shape is not None and _prod(shape***REMOVED*** > 1***REMOVED***:
                    # Inject internal padding to the end of the sub-item
                    value = _add_trailing_padding(value, intra_padding***REMOVED***
                else:
                    # We can postpone the injection of internal padding,
                    # as the item appears at most once
                    extra_offset += intra_padding

            # Update common alignment
            common_alignment = (align*common_alignment
                                / _gcd(align, common_alignment***REMOVED******REMOVED***

        # Convert itemsize to sub-array
        if itemsize != 1:
            value = dtype((value, (itemsize,***REMOVED******REMOVED******REMOVED***

        # Sub-arrays (2***REMOVED***
        if shape is not None:
            value = dtype((value, shape***REMOVED******REMOVED***

        # Field name
        this_explicit_name = False
        if spec and spec.startswith(':'***REMOVED***:
            i = spec[1:***REMOVED***.index(':'***REMOVED*** + 1
            name = spec[1:i***REMOVED***
            spec = spec[i+1:***REMOVED***
            explicit_name = True
            this_explicit_name = True
        else:
            name = get_dummy_name(***REMOVED***

        if not is_padding or this_explicit_name:
            if name in fields:
                raise RuntimeError("Duplicate field name '%s' in PEP3118 format"
                                   % name***REMOVED***
            fields[name***REMOVED*** = (value, offset***REMOVED***
            if not this_explicit_name:
                next_dummy_name(***REMOVED***

        byteorder = next_byteorder

        offset += value.itemsize
        offset += extra_offset

    # Check if this was a simple 1-item type
    if (len(fields***REMOVED*** == 1 and not explicit_name and
            fields['f0'***REMOVED***[1***REMOVED*** == 0 and not is_subdtype***REMOVED***:
        ret = fields['f0'***REMOVED***[0***REMOVED***
    else:
        ret = dtype(fields***REMOVED***

    # Trailing padding must be explicitly added
    padding = offset - ret.itemsize
    if byteorder == '@':
        padding += (-offset***REMOVED*** % common_alignment
    if is_padding and not this_explicit_name:
        ret = _add_trailing_padding(ret, padding***REMOVED***

    # Finished
    if is_subdtype:
        return ret, spec, common_alignment, byteorder
    else:
        return ret

def _add_trailing_padding(value, padding***REMOVED***:
    ***REMOVED***Inject the specified number of padding bytes at the end of a dtype***REMOVED***
    if value.fields is None:
        vfields = {'f0': (value, 0***REMOVED******REMOVED***
    else:
        vfields = dict(value.fields***REMOVED***

    if (value.names and value.names[-1***REMOVED*** == '' and
           value[''***REMOVED***.char == 'V'***REMOVED***:
        # A trailing padding field is already present
        vfields[''***REMOVED*** = ('V%d' % (vfields[''***REMOVED***[0***REMOVED***.itemsize + padding***REMOVED***,
                       vfields[''***REMOVED***[1***REMOVED******REMOVED***
        value = dtype(vfields***REMOVED***
    else:
        # Get a free name for the padding field
        j = 0
        while True:
            name = 'pad%d' % j
            if name not in vfields:
                vfields[name***REMOVED*** = ('V%d' % padding, value.itemsize***REMOVED***
                break
            j += 1

        value = dtype(vfields***REMOVED***
        if '' not in vfields:
            # Strip out the name of the padding field
            names = list(value.names***REMOVED***
            names[-1***REMOVED*** = ''
            value.names = tuple(names***REMOVED***
    return value

def _prod(a***REMOVED***:
    p = 1
    for x in a:
        p *= x
    return p

def _gcd(a, b***REMOVED***:
    ***REMOVED***Calculate the greatest common divisor of a and b***REMOVED***
    while b:
        a, b = b, a % b
    return a

# Exception used in shares_memory(***REMOVED***
class TooHardError(RuntimeError***REMOVED***:
    pass

# -*- coding: utf-8 -
#
# This file is part of gunicorn released under the MIT license.
# See the NOTICE for more information.

import re
import socket
from errno import ENOTCONN

from gunicorn._compat import bytes_to_str
from gunicorn.http.unreader import SocketUnreader
from gunicorn.http.body import ChunkedReader, LengthReader, EOFReader, Body
from gunicorn.http.errors import (InvalidHeader, InvalidHeaderName, NoMoreData,
    InvalidRequestLine, InvalidRequestMethod, InvalidHTTPVersion,
    LimitRequestLine, LimitRequestHeaders***REMOVED***
from gunicorn.http.errors import InvalidProxyLine, ForbiddenProxyRequest
from gunicorn.six import BytesIO
from gunicorn._compat import urlsplit

MAX_REQUEST_LINE = 8190
MAX_HEADERS = 32768
MAX_HEADERFIELD_SIZE = 8190

HEADER_RE = re.compile("[\x00-\x1F\x7F(***REMOVED***<>@,;:\[\***REMOVED***={***REMOVED*** \t\\\\\"***REMOVED***"***REMOVED***
METH_RE = re.compile(r"[A-Z0-9$-_.***REMOVED***{3,20***REMOVED***"***REMOVED***
VERSION_RE = re.compile(r"HTTP/(\d+***REMOVED***.(\d+***REMOVED***"***REMOVED***


class Message(object***REMOVED***:
    def __init__(self, cfg, unreader***REMOVED***:
        self.cfg = cfg
        self.unreader = unreader
        self.version = None
        self.headers = [***REMOVED***
        self.trailers = [***REMOVED***
        self.body = None

        # set headers limits
        self.limit_request_fields = cfg.limit_request_fields
        if (self.limit_request_fields <= 0
            or self.limit_request_fields > MAX_HEADERS***REMOVED***:
            self.limit_request_fields = MAX_HEADERS
        self.limit_request_field_size = cfg.limit_request_field_size
        if (self.limit_request_field_size < 0
            or self.limit_request_field_size > MAX_HEADERFIELD_SIZE***REMOVED***:
            self.limit_request_field_size = MAX_HEADERFIELD_SIZE

        # set max header buffer size
        max_header_field_size = self.limit_request_field_size or MAX_HEADERFIELD_SIZE
        self.max_buffer_headers = self.limit_request_fields * \
            (max_header_field_size + 2***REMOVED*** + 4

        unused = self.parse(self.unreader***REMOVED***
        self.unreader.unread(unused***REMOVED***
        self.set_body_reader(***REMOVED***

    def parse(self***REMOVED***:
        raise NotImplementedError(***REMOVED***

    def parse_headers(self, data***REMOVED***:
        headers = [***REMOVED***

        # Split lines on \r\n keeping the \r\n on each line
        lines = [bytes_to_str(line***REMOVED*** + "\r\n" for line in data.split(b"\r\n"***REMOVED******REMOVED***

        # Parse headers into key/value pairs paying attention
        # to continuation lines.
        while len(lines***REMOVED***:
            if len(headers***REMOVED*** >= self.limit_request_fields:
                raise LimitRequestHeaders("limit request headers fields"***REMOVED***

            # Parse initial header name : value pair.
            curr = lines.pop(0***REMOVED***
            header_length = len(curr***REMOVED***
            if curr.find(":"***REMOVED*** < 0:
                raise InvalidHeader(curr.strip(***REMOVED******REMOVED***
            name, value = curr.split(":", 1***REMOVED***
            name = name.rstrip(" \t"***REMOVED***.upper(***REMOVED***
            if HEADER_RE.search(name***REMOVED***:
                raise InvalidHeaderName(name***REMOVED***

            name, value = name.strip(***REMOVED***, [value.lstrip(***REMOVED******REMOVED***

            # Consume value continuation lines
            while len(lines***REMOVED*** and lines[0***REMOVED***.startswith((" ", "\t"***REMOVED******REMOVED***:
                curr = lines.pop(0***REMOVED***
                header_length += len(curr***REMOVED***
                if header_length > self.limit_request_field_size > 0:
                    raise LimitRequestHeaders("limit request headers "
                            + "fields size"***REMOVED***
                value.append(curr***REMOVED***
            value = ''.join(value***REMOVED***.rstrip(***REMOVED***

            if header_length > self.limit_request_field_size > 0:
                raise LimitRequestHeaders("limit request headers fields size"***REMOVED***
            headers.append((name, value***REMOVED******REMOVED***
        return headers

    def set_body_reader(self***REMOVED***:
        chunked = False
        content_length = None
        for (name, value***REMOVED*** in self.headers:
            if name == "CONTENT-LENGTH":
                content_length = value
            elif name == "TRANSFER-ENCODING":
                chunked = value.lower(***REMOVED*** == "chunked"
            elif name == "SEC-WEBSOCKET-KEY1":
                content_length = 8

        if chunked:
            self.body = Body(ChunkedReader(self, self.unreader***REMOVED******REMOVED***
        elif content_length is not None:
            ***REMOVED***
                content_length = int(content_length***REMOVED***
            except ValueError:
                raise InvalidHeader("CONTENT-LENGTH", req=self***REMOVED***

            if content_length < 0:
                raise InvalidHeader("CONTENT-LENGTH", req=self***REMOVED***

            self.body = Body(LengthReader(self.unreader, content_length***REMOVED******REMOVED***
        else:
            self.body = Body(EOFReader(self.unreader***REMOVED******REMOVED***

    def should_close(self***REMOVED***:
        for (h, v***REMOVED*** in self.headers:
            if h == "CONNECTION":
                v = v.lower(***REMOVED***.strip(***REMOVED***
                if v == "close":
                    return True
                elif v == "keep-alive":
                    return False
                break
        return self.version <= (1, 0***REMOVED***


class Request(Message***REMOVED***:
    def __init__(self, cfg, unreader, req_number=1***REMOVED***:
        self.method = None
        self.uri = None
        self.path = None
        self.query = None
        self.fragment = None

        # get max request line size
        self.limit_request_line = cfg.limit_request_line
        if (self.limit_request_line < 0
            or self.limit_request_line >= MAX_REQUEST_LINE***REMOVED***:
            self.limit_request_line = MAX_REQUEST_LINE

        self.req_number = req_number
        self.proxy_protocol_info = None
        super(Request, self***REMOVED***.__init__(cfg, unreader***REMOVED***

    def get_data(self, unreader, buf, stop=False***REMOVED***:
        data = unreader.read(***REMOVED***
        if not data:
            if stop:
                raise StopIteration(***REMOVED***
            raise NoMoreData(buf.getvalue(***REMOVED******REMOVED***
        buf.write(data***REMOVED***

    def parse(self, unreader***REMOVED***:
        buf = BytesIO(***REMOVED***
        self.get_data(unreader, buf, stop=True***REMOVED***

        # get request line
        line, rbuf = self.read_line(unreader, buf, self.limit_request_line***REMOVED***

        # proxy protocol
        if self.proxy_protocol(bytes_to_str(line***REMOVED******REMOVED***:
            # get next request line
            buf = BytesIO(***REMOVED***
            buf.write(rbuf***REMOVED***
            line, rbuf = self.read_line(unreader, buf, self.limit_request_line***REMOVED***

        self.parse_request_line(bytes_to_str(line***REMOVED******REMOVED***
        buf = BytesIO(***REMOVED***
        buf.write(rbuf***REMOVED***

        # Headers
        data = buf.getvalue(***REMOVED***
        idx = data.find(b"\r\n\r\n"***REMOVED***

        done = data[:2***REMOVED*** == b"\r\n"
        while True:
            idx = data.find(b"\r\n\r\n"***REMOVED***
            done = data[:2***REMOVED*** == b"\r\n"

            if idx < 0 and not done:
                self.get_data(unreader, buf***REMOVED***
                data = buf.getvalue(***REMOVED***
                if len(data***REMOVED*** > self.max_buffer_headers:
                    raise LimitRequestHeaders("max buffer headers"***REMOVED***
            else:
                break

        if done:
            self.unreader.unread(data[2:***REMOVED******REMOVED***
            return b""

        self.headers = self.parse_headers(data[:idx***REMOVED******REMOVED***

        ret = data[idx + 4:***REMOVED***
        buf = BytesIO(***REMOVED***
        return ret

    def read_line(self, unreader, buf, limit=0***REMOVED***:
        data = buf.getvalue(***REMOVED***

        while True:
            idx = data.find(b"\r\n"***REMOVED***
            if idx >= 0:
                # check if the request line is too large
                if idx > limit > 0:
                    raise LimitRequestLine(idx, limit***REMOVED***
                break
            elif len(data***REMOVED*** - 2 > limit > 0:
                raise LimitRequestLine(len(data***REMOVED***, limit***REMOVED***
            self.get_data(unreader, buf***REMOVED***
            data = buf.getvalue(***REMOVED***

        return (data[:idx***REMOVED***,  # request line,
                data[idx + 2:***REMOVED******REMOVED***  # residue in the buffer, skip \r\n

    def proxy_protocol(self, line***REMOVED***:
        ***REMOVED***\
        Detect, check and parse proxy protocol.

        :raises: ForbiddenProxyRequest, InvalidProxyLine.
        :return: True for proxy protocol line else False
        ***REMOVED***
        if not self.cfg.proxy_protocol:
            return False

        if self.req_number != 1:
            return False

        if not line.startswith("PROXY"***REMOVED***:
            return False

        self.proxy_protocol_access_check(***REMOVED***
        self.parse_proxy_protocol(line***REMOVED***

        return True

    def proxy_protocol_access_check(self***REMOVED***:
        # check in allow list
        if isinstance(self.unreader, SocketUnreader***REMOVED***:
            ***REMOVED***
                remote_host = self.unreader.sock.getpeername(***REMOVED***[0***REMOVED***
            except socket.error as e:
                if e.args[0***REMOVED*** == ENOTCONN:
                    raise ForbiddenProxyRequest("UNKNOW"***REMOVED***
                raise
            if ("*" not in self.cfg.proxy_allow_ips and
                    remote_host not in self.cfg.proxy_allow_ips***REMOVED***:
                raise ForbiddenProxyRequest(remote_host***REMOVED***

    def parse_proxy_protocol(self, line***REMOVED***:
        bits = line.split(***REMOVED***

        if len(bits***REMOVED*** != 6:
            raise InvalidProxyLine(line***REMOVED***

        # Extract data
        proto = bits[1***REMOVED***
        s_addr = bits[2***REMOVED***
        d_addr = bits[3***REMOVED***

        # Validation
        if proto not in ["TCP4", "TCP6"***REMOVED***:
            raise InvalidProxyLine("protocol '%s' not supported" % proto***REMOVED***
        if proto == "TCP4":
            ***REMOVED***
                socket.inet_pton(socket.AF_INET, s_addr***REMOVED***
                socket.inet_pton(socket.AF_INET, d_addr***REMOVED***
            except socket.error:
                raise InvalidProxyLine(line***REMOVED***
        elif proto == "TCP6":
            ***REMOVED***
                socket.inet_pton(socket.AF_INET6, s_addr***REMOVED***
                socket.inet_pton(socket.AF_INET6, d_addr***REMOVED***
            except socket.error:
                raise InvalidProxyLine(line***REMOVED***

        ***REMOVED***
            s_port = int(bits[4***REMOVED******REMOVED***
            d_port = int(bits[5***REMOVED******REMOVED***
        except ValueError:
            raise InvalidProxyLine("invalid port %s" % line***REMOVED***

        if not ((0 <= s_port <= 65535***REMOVED*** and (0 <= d_port <= 65535***REMOVED******REMOVED***:
            raise InvalidProxyLine("invalid port %s" % line***REMOVED***

        # Set data
        self.proxy_protocol_info = {
            "proxy_protocol": proto,
            "client_addr": s_addr,
            "client_port": s_port,
            "proxy_addr": d_addr,
            "proxy_port": d_port
    ***REMOVED***

    def parse_request_line(self, line***REMOVED***:
        bits = line.split(None, 2***REMOVED***
        if len(bits***REMOVED*** != 3:
            raise InvalidRequestLine(line***REMOVED***

        # Method
        if not METH_RE.match(bits[0***REMOVED******REMOVED***:
            raise InvalidRequestMethod(bits[0***REMOVED******REMOVED***
        self.method = bits[0***REMOVED***.upper(***REMOVED***

        # URI
        # When the path starts with //, urlsplit considers it as a
        # relative uri while the RDF says it shouldnt
        # http://www.w3.org/Protocols/rfc2616/rfc2616-sec5.html#sec5.1.2
        # considers it as an absolute url.
        # fix issue #297
        if bits[1***REMOVED***.startswith("//"***REMOVED***:
            self.uri = bits[1***REMOVED***[1:***REMOVED***
        else:
            self.uri = bits[1***REMOVED***

        ***REMOVED***
            parts = urlsplit(self.uri***REMOVED***
        except ValueError:
            raise InvalidRequestLine(line***REMOVED***
        self.path = parts.path or ""
        self.query = parts.query or ""
        self.fragment = parts.fragment or ""

        # Version
        match = VERSION_RE.match(bits[2***REMOVED******REMOVED***
        if match is None:
            raise InvalidHTTPVersion(bits[2***REMOVED******REMOVED***
        self.version = (int(match.group(1***REMOVED******REMOVED***, int(match.group(2***REMOVED******REMOVED******REMOVED***

    def set_body_reader(self***REMOVED***:
        super(Request, self***REMOVED***.set_body_reader(***REMOVED***
        if isinstance(self.body.reader, EOFReader***REMOVED***:
            self.body = Body(LengthReader(self.unreader, 0***REMOVED******REMOVED***

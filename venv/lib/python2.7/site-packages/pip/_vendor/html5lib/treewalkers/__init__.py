***REMOVED***A collection of modules for iterating through different kinds of
tree, generating tokens identical to those produced by the tokenizer
module.

To create a tree walker for a new type of tree, you need to do
implement a tree walker object (called TreeWalker by convention***REMOVED*** that
implements a 'serialize' method taking a tree as sole argument and
returning an iterator generating tokens.
***REMOVED***

from __future__ import absolute_import, division, unicode_literals

__all__ = ["getTreeWalker", "pprint", "dom", "etree", "genshistream", "lxmletree",
           "pulldom"***REMOVED***

import sys

from .. import constants
from ..utils import default_etree

treeWalkerCache = {***REMOVED***


def getTreeWalker(treeType, implementation=None, **kwargs***REMOVED***:
    ***REMOVED***Get a TreeWalker class for various types of tree with built-in support

    treeType - the name of the tree type required (case-insensitive***REMOVED***. Supported
               values are:

                "dom" - The xml.dom.minidom DOM implementation
                "pulldom" - The xml.dom.pulldom event stream
                "etree" - A generic walker for tree implementations exposing an
                          elementtree-like interface (known to work with
                          ElementTree, cElementTree and lxml.etree***REMOVED***.
                "lxml" - Optimized walker for lxml.etree
                "genshi" - a Genshi stream

    implementation - (Currently applies to the "etree" tree type only***REMOVED***. A module
                      implementing the tree type e.g. xml.etree.ElementTree or
                      cElementTree.***REMOVED***

    treeType = treeType.lower(***REMOVED***
    if treeType not in treeWalkerCache:
        if treeType in ("dom", "pulldom"***REMOVED***:
            name = "%s.%s" % (__name__, treeType***REMOVED***
            __import__(name***REMOVED***
            mod = sys.modules[name***REMOVED***
            treeWalkerCache[treeType***REMOVED*** = mod.TreeWalker
        elif treeType == "genshi":
            from . import genshistream
            treeWalkerCache[treeType***REMOVED*** = genshistream.TreeWalker
        elif treeType == "lxml":
            from . import lxmletree
            treeWalkerCache[treeType***REMOVED*** = lxmletree.TreeWalker
        elif treeType == "etree":
            from . import etree
            if implementation is None:
                implementation = default_etree
            # XXX: NEVER cache here, caching is done in the etree submodule
            return etree.getETreeModule(implementation, **kwargs***REMOVED***.TreeWalker
    return treeWalkerCache.get(treeType***REMOVED***


def concatenateCharacterTokens(tokens***REMOVED***:
    pendingCharacters = [***REMOVED***
    for token in tokens:
        type = token["type"***REMOVED***
        if type in ("Characters", "SpaceCharacters"***REMOVED***:
            pendingCharacters.append(token["data"***REMOVED******REMOVED***
        else:
            if pendingCharacters:
                yield {"type": "Characters", "data": "".join(pendingCharacters***REMOVED******REMOVED***
                pendingCharacters = [***REMOVED***
            yield token
    if pendingCharacters:
        yield {"type": "Characters", "data": "".join(pendingCharacters***REMOVED******REMOVED***


def pprint(walker***REMOVED***:
    ***REMOVED***Pretty printer for tree walkers***REMOVED***
    output = [***REMOVED***
    indent = 0
    for token in concatenateCharacterTokens(walker***REMOVED***:
        type = token["type"***REMOVED***
        if type in ("StartTag", "EmptyTag"***REMOVED***:
            # tag name
            if token["namespace"***REMOVED*** and token["namespace"***REMOVED*** != constants.namespaces["html"***REMOVED***:
                if token["namespace"***REMOVED*** in constants.prefixes:
                    ns = constants.prefixes[token["namespace"***REMOVED******REMOVED***
                else:
                    ns = token["namespace"***REMOVED***
                name = "%s %s" % (ns, token["name"***REMOVED******REMOVED***
            else:
                name = token["name"***REMOVED***
            output.append("%s<%s>" % (" " * indent, name***REMOVED******REMOVED***
            indent += 2
            # attributes (sorted for consistent ordering***REMOVED***
            attrs = token["data"***REMOVED***
            for (namespace, localname***REMOVED***, value in sorted(attrs.items(***REMOVED******REMOVED***:
                if namespace:
                    if namespace in constants.prefixes:
                        ns = constants.prefixes[namespace***REMOVED***
                    else:
                        ns = namespace
                    name = "%s %s" % (ns, localname***REMOVED***
                else:
                    name = localname
                output.append("%s%s=\"%s\"" % (" " * indent, name, value***REMOVED******REMOVED***
            # self-closing
            if type == "EmptyTag":
                indent -= 2

        elif type == "EndTag":
            indent -= 2

        elif type == "Comment":
            output.append("%s<!-- %s -->" % (" " * indent, token["data"***REMOVED******REMOVED******REMOVED***

        elif type == "Doctype":
            if token["name"***REMOVED***:
                if token["publicId"***REMOVED***:
                    output.append(***REMOVED***%s<!DOCTYPE %s "%s" "%s">***REMOVED*** %
                                  (" " * indent,
                                   token["name"***REMOVED***,
                                   token["publicId"***REMOVED***,
                                   token["systemId"***REMOVED*** if token["systemId"***REMOVED*** else ""***REMOVED******REMOVED***
                elif token["systemId"***REMOVED***:
                    output.append(***REMOVED***%s<!DOCTYPE %s "" "%s">***REMOVED*** %
                                  (" " * indent,
                                   token["name"***REMOVED***,
                                   token["systemId"***REMOVED******REMOVED******REMOVED***
                else:
                    output.append("%s<!DOCTYPE %s>" % (" " * indent,
                                                       token["name"***REMOVED******REMOVED******REMOVED***
            else:
                output.append("%s<!DOCTYPE >" % (" " * indent,***REMOVED******REMOVED***

        elif type == "Characters":
            output.append("%s\"%s\"" % (" " * indent, token["data"***REMOVED******REMOVED******REMOVED***

        elif type == "SpaceCharacters":
            assert False, "concatenateCharacterTokens should have got rid of all Space tokens"

        else:
            raise ValueError("Unknown token type, %s" % type***REMOVED***

    return "\n".join(output***REMOVED***

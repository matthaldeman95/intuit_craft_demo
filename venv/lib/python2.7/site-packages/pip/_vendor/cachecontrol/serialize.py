import base64
import io
import json
import zlib

from pip._vendor.requests.structures import CaseInsensitiveDict

from .compat import HTTPResponse, pickle, text_type


def _b64_encode_bytes(b***REMOVED***:
    return base64.b64encode(b***REMOVED***.decode("ascii"***REMOVED***


def _b64_encode_str(s***REMOVED***:
    return _b64_encode_bytes(s.encode("utf8"***REMOVED******REMOVED***


def _b64_encode(s***REMOVED***:
    if isinstance(s, text_type***REMOVED***:
        return _b64_encode_str(s***REMOVED***
    return _b64_encode_bytes(s***REMOVED***


def _b64_decode_bytes(b***REMOVED***:
    return base64.b64decode(b.encode("ascii"***REMOVED******REMOVED***


def _b64_decode_str(s***REMOVED***:
    return _b64_decode_bytes(s***REMOVED***.decode("utf8"***REMOVED***


class Serializer(object***REMOVED***:

    def dumps(self, request, response, body=None***REMOVED***:
        response_headers = CaseInsensitiveDict(response.headers***REMOVED***

        if body is None:
            body = response.read(decode_content=False***REMOVED***

            # NOTE: 99% sure this is dead code. I'm only leaving it
            #       here b/c I don't have a test yet to prove
            #       it. Basically, before using
            #       `cachecontrol.filewrapper.CallbackFileWrapper`,
            #       this made an effort to reset the file handle. The
            #       `CallbackFileWrapper` short circuits this code by
            #       setting the body as the content is consumed, the
            #       result being a `body` argument is *always* passed
            #       into cache_response, and in turn,
            #       `Serializer.dump`.
            response._fp = io.BytesIO(body***REMOVED***

        data = {
            "response": {
                "body": _b64_encode_bytes(body***REMOVED***,
                "headers": dict(
                    (_b64_encode(k***REMOVED***, _b64_encode(v***REMOVED******REMOVED***
                    for k, v in response.headers.items(***REMOVED***
                ***REMOVED***,
                "status": response.status,
                "version": response.version,
                "reason": _b64_encode_str(response.reason***REMOVED***,
                "strict": response.strict,
                "decode_content": response.decode_content,
    ***REMOVED***
    ***REMOVED***

        # Construct our vary headers
        data["vary"***REMOVED*** = {***REMOVED***
        if "vary" in response_headers:
            varied_headers = response_headers['vary'***REMOVED***.split(','***REMOVED***
            for header in varied_headers:
                header = header.strip(***REMOVED***
                data["vary"***REMOVED***[header***REMOVED*** = request.headers.get(header, None***REMOVED***

        # Encode our Vary headers to ensure they can be serialized as JSON
        data["vary"***REMOVED*** = dict(
            (_b64_encode(k***REMOVED***, _b64_encode(v***REMOVED*** if v is not None else v***REMOVED***
            for k, v in data["vary"***REMOVED***.items(***REMOVED***
        ***REMOVED***

        return b",".join([
            b"cc=2",
            zlib.compress(
                json.dumps(
                    data, separators=(",", ":"***REMOVED***, sort_keys=True,
                ***REMOVED***.encode("utf8"***REMOVED***,
            ***REMOVED***,
        ***REMOVED******REMOVED***

    def loads(self, request, data***REMOVED***:
        # Short circuit if we've been given an empty set of data
        if not data:
            return

        # Determine what version of the serializer the data was serialized
        # with
        ***REMOVED***
            ver, data = data.split(b",", 1***REMOVED***
        except ValueError:
            ver = b"cc=0"

        # Make sure that our "ver" is actually a version and isn't a false
        # positive from a , being in the data stream.
        if ver[:3***REMOVED*** != b"cc=":
            data = ver + data
            ver = b"cc=0"

        # Get the version number out of the cc=N
        ver = ver.split(b"=", 1***REMOVED***[-1***REMOVED***.decode("ascii"***REMOVED***

        # Dispatch to the actual load method for the given version
        ***REMOVED***
            return getattr(self, "_loads_v{0***REMOVED***".format(ver***REMOVED******REMOVED***(request, data***REMOVED***
        except AttributeError:
            # This is a version we don't have a loads function for, so we'll
            # just treat it as a miss and return None
            return

    def prepare_response(self, request, cached***REMOVED***:
        ***REMOVED***Verify our vary headers match and construct a real urllib3
        HTTPResponse object.
        ***REMOVED***
        # Special case the '*' Vary value as it means we cannot actually
        # determine if the cached response is suitable for this request.
        if "*" in cached.get("vary", {***REMOVED******REMOVED***:
            return

        # Ensure that the Vary headers for the cached response match our
        # request
        for header, value in cached.get("vary", {***REMOVED******REMOVED***.items(***REMOVED***:
            if request.headers.get(header, None***REMOVED*** != value:
                return

        body_raw = cached["response"***REMOVED***.pop("body"***REMOVED***

        ***REMOVED***
            body = io.BytesIO(body_raw***REMOVED***
        except TypeError:
            # This can happen if cachecontrol serialized to v1 format (pickle***REMOVED***
            # using Python 2. A Python 2 str(byte string***REMOVED*** will be unpickled as
            # a Python 3 str (unicode string***REMOVED***, which will cause the above to
            # fail with:
            #
            #     TypeError: 'str' does not support the buffer interface
            body = io.BytesIO(body_raw.encode('utf8'***REMOVED******REMOVED***

        return HTTPResponse(
            body=body,
            preload_content=False,
            **cached["response"***REMOVED***
        ***REMOVED***

    def _loads_v0(self, request, data***REMOVED***:
        # The original legacy cache data. This doesn't contain enough
        # information to construct everything we need, so we'll treat this as
        # a miss.
        return

    def _loads_v1(self, request, data***REMOVED***:
        ***REMOVED***
            cached = pickle.loads(data***REMOVED***
        except ValueError:
            return

        return self.prepare_response(request, cached***REMOVED***

    def _loads_v2(self, request, data***REMOVED***:
        ***REMOVED***
            cached = json.loads(zlib.decompress(data***REMOVED***.decode("utf8"***REMOVED******REMOVED***
        except ValueError:
            return

        # We need to decode the items that we've base64 encoded
        cached["response"***REMOVED***["body"***REMOVED*** = _b64_decode_bytes(
            cached["response"***REMOVED***["body"***REMOVED***
        ***REMOVED***
        cached["response"***REMOVED***["headers"***REMOVED*** = dict(
            (_b64_decode_str(k***REMOVED***, _b64_decode_str(v***REMOVED******REMOVED***
            for k, v in cached["response"***REMOVED***["headers"***REMOVED***.items(***REMOVED***
        ***REMOVED***
        cached["response"***REMOVED***["reason"***REMOVED*** = _b64_decode_str(
            cached["response"***REMOVED***["reason"***REMOVED***,
        ***REMOVED***
        cached["vary"***REMOVED*** = dict(
            (_b64_decode_str(k***REMOVED***, _b64_decode_str(v***REMOVED*** if v is not None else v***REMOVED***
            for k, v in cached["vary"***REMOVED***.items(***REMOVED***
        ***REMOVED***

        return self.prepare_response(request, cached***REMOVED***

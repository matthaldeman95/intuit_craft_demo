"Database cache backend."
import base64
from datetime import datetime

from django.conf import settings
from django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache
from django.db import DatabaseError, connections, models, router, transaction
from django.utils import six, timezone
from django.utils.encoding import force_bytes

***REMOVED***
    from django.utils.six.moves import cPickle as pickle
except ImportError:
    import pickle


class Options(object***REMOVED***:
    ***REMOVED***A class that will quack like a Django model _meta class.

    This allows cache operations to be controlled by the router
    ***REMOVED***
    def __init__(self, table***REMOVED***:
        self.db_table = table
        self.app_label = 'django_cache'
        self.model_name = 'cacheentry'
        self.verbose_name = 'cache entry'
        self.verbose_name_plural = 'cache entries'
        self.object_name = 'CacheEntry'
        self.abstract = False
        self.managed = True
        self.proxy = False
        self.swapped = False


class BaseDatabaseCache(BaseCache***REMOVED***:
    def __init__(self, table, params***REMOVED***:
        BaseCache.__init__(self, params***REMOVED***
        self._table = table

        class CacheEntry(object***REMOVED***:
            _meta = Options(table***REMOVED***
        self.cache_model_class = CacheEntry


class DatabaseCache(BaseDatabaseCache***REMOVED***:

    # This class uses cursors provided by the database connection. This means
    # it reads expiration values as aware or naive datetimes, depending on the
    # value of USE_TZ and whether the database supports time zones. The ORM's
    # conversion and adaptation infrastructure is then used to avoid comparing
    # aware and naive datetimes accidentally.

    def get(self, key, default=None, version=None***REMOVED***:
        key = self.make_key(key, version=version***REMOVED***
        self.validate_key(key***REMOVED***
        db = router.db_for_read(self.cache_model_class***REMOVED***
        connection = connections[db***REMOVED***
        table = connection.ops.quote_name(self._table***REMOVED***

        with connection.cursor(***REMOVED*** as cursor:
            cursor.execute("SELECT cache_key, value, expires FROM %s "
                           "WHERE cache_key = %%s" % table, [key***REMOVED******REMOVED***
            row = cursor.fetchone(***REMOVED***
        if row is None:
            return default

        expires = row[2***REMOVED***
        expression = models.Expression(output_field=models.DateTimeField(***REMOVED******REMOVED***
        for converter in (connection.ops.get_db_converters(expression***REMOVED*** +
                          expression.get_db_converters(connection***REMOVED******REMOVED***:
            expires = converter(expires, expression, connection, {***REMOVED******REMOVED***

        if expires < timezone.now(***REMOVED***:
            db = router.db_for_write(self.cache_model_class***REMOVED***
            connection = connections[db***REMOVED***
            with connection.cursor(***REMOVED*** as cursor:
                cursor.execute("DELETE FROM %s "
                               "WHERE cache_key = %%s" % table, [key***REMOVED******REMOVED***
            return default

        value = connection.ops.process_clob(row[1***REMOVED******REMOVED***
        return pickle.loads(base64.b64decode(force_bytes(value***REMOVED******REMOVED******REMOVED***

    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None***REMOVED***:
        key = self.make_key(key, version=version***REMOVED***
        self.validate_key(key***REMOVED***
        self._base_set('set', key, value, timeout***REMOVED***

    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None***REMOVED***:
        key = self.make_key(key, version=version***REMOVED***
        self.validate_key(key***REMOVED***
        return self._base_set('add', key, value, timeout***REMOVED***

    def _base_set(self, mode, key, value, timeout=DEFAULT_TIMEOUT***REMOVED***:
        timeout = self.get_backend_timeout(timeout***REMOVED***
        db = router.db_for_write(self.cache_model_class***REMOVED***
        connection = connections[db***REMOVED***
        table = connection.ops.quote_name(self._table***REMOVED***

        with connection.cursor(***REMOVED*** as cursor:
            cursor.execute("SELECT COUNT(****REMOVED*** FROM %s" % table***REMOVED***
            num = cursor.fetchone(***REMOVED***[0***REMOVED***
            now = timezone.now(***REMOVED***
            now = now.replace(microsecond=0***REMOVED***
            if timeout is None:
                exp = datetime.max
            elif settings.USE_TZ:
                exp = datetime.utcfromtimestamp(timeout***REMOVED***
            else:
                exp = datetime.fromtimestamp(timeout***REMOVED***
            exp = exp.replace(microsecond=0***REMOVED***
            if num > self._max_entries:
                self._cull(db, cursor, now***REMOVED***
            pickled = pickle.dumps(value, pickle.HIGHEST_PROTOCOL***REMOVED***
            b64encoded = base64.b64encode(pickled***REMOVED***
            # The DB column is expecting a string, so make sure the value is a
            # string, not bytes. Refs #19274.
            if six.PY3:
                b64encoded = b64encoded.decode('latin1'***REMOVED***
            ***REMOVED***
                # Note: typecasting for datetimes is needed by some 3rd party
                # database backends. All core backends work without typecasting,
                # so be careful about changes here - test suite will NOT pick
                # regressions.
                with transaction.atomic(using=db***REMOVED***:
                    cursor.execute("SELECT cache_key, expires FROM %s "
                                   "WHERE cache_key = %%s" % table, [key***REMOVED******REMOVED***
                    result = cursor.fetchone(***REMOVED***

                    if result:
                        current_expires = result[1***REMOVED***
                        expression = models.Expression(output_field=models.DateTimeField(***REMOVED******REMOVED***
                        for converter in (connection.ops.get_db_converters(expression***REMOVED*** +
                                          expression.get_db_converters(connection***REMOVED******REMOVED***:
                            current_expires = converter(current_expires, expression, connection, {***REMOVED******REMOVED***

                    exp = connection.ops.adapt_datetimefield_value(exp***REMOVED***
                    if result and (mode == 'set' or (mode == 'add' and current_expires < now***REMOVED******REMOVED***:
                        cursor.execute("UPDATE %s SET value = %%s, expires = %%s "
                                       "WHERE cache_key = %%s" % table,
                                       [b64encoded, exp, key***REMOVED******REMOVED***
                    else:
                        cursor.execute("INSERT INTO %s (cache_key, value, expires***REMOVED*** "
                                       "VALUES (%%s, %%s, %%s***REMOVED***" % table,
                                       [key, b64encoded, exp***REMOVED******REMOVED***
            except DatabaseError:
                # To be threadsafe, updates/inserts are allowed to fail silently
                return False
            else:
                return True

    def delete(self, key, version=None***REMOVED***:
        key = self.make_key(key, version=version***REMOVED***
        self.validate_key(key***REMOVED***

        db = router.db_for_write(self.cache_model_class***REMOVED***
        connection = connections[db***REMOVED***
        table = connection.ops.quote_name(self._table***REMOVED***

        with connection.cursor(***REMOVED*** as cursor:
            cursor.execute("DELETE FROM %s WHERE cache_key = %%s" % table, [key***REMOVED******REMOVED***

    def has_key(self, key, version=None***REMOVED***:
        key = self.make_key(key, version=version***REMOVED***
        self.validate_key(key***REMOVED***

        db = router.db_for_read(self.cache_model_class***REMOVED***
        connection = connections[db***REMOVED***
        table = connection.ops.quote_name(self._table***REMOVED***

        if settings.USE_TZ:
            now = datetime.utcnow(***REMOVED***
        else:
            now = datetime.now(***REMOVED***
        now = now.replace(microsecond=0***REMOVED***

        with connection.cursor(***REMOVED*** as cursor:
            cursor.execute("SELECT cache_key FROM %s "
                           "WHERE cache_key = %%s and expires > %%s" % table,
                           [key, connection.ops.adapt_datetimefield_value(now***REMOVED******REMOVED******REMOVED***
            return cursor.fetchone(***REMOVED*** is not None

    def _cull(self, db, cursor, now***REMOVED***:
        if self._cull_frequency == 0:
            self.clear(***REMOVED***
        else:
            connection = connections[db***REMOVED***
            table = connection.ops.quote_name(self._table***REMOVED***
            cursor.execute("DELETE FROM %s WHERE expires < %%s" % table,
                           [connection.ops.adapt_datetimefield_value(now***REMOVED******REMOVED******REMOVED***
            cursor.execute("SELECT COUNT(****REMOVED*** FROM %s" % table***REMOVED***
            num = cursor.fetchone(***REMOVED***[0***REMOVED***
            if num > self._max_entries:
                cull_num = num // self._cull_frequency
                cursor.execute(
                    connection.ops.cache_key_culling_sql(***REMOVED*** % table,
                    [cull_num***REMOVED******REMOVED***
                cursor.execute("DELETE FROM %s "
                               "WHERE cache_key < %%s" % table,
                               [cursor.fetchone(***REMOVED***[0***REMOVED******REMOVED******REMOVED***

    def clear(self***REMOVED***:
        db = router.db_for_write(self.cache_model_class***REMOVED***
        connection = connections[db***REMOVED***
        table = connection.ops.quote_name(self._table***REMOVED***
        with connection.cursor(***REMOVED*** as cursor:
            cursor.execute('DELETE FROM %s' % table***REMOVED***
